{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Credit Card Default Risk Analysis\n", "### Predictive Modeling \u00b7 Risk Analysis \u00b7 Profit Optimization\n\n", "This notebook walks through a full professional workflow:\n", "- Data loading and basic inspection\n", "- Data cleaning and feature engineering\n", "- Exploratory Data Analysis (EDA)\n", "- Predictive modeling (Logistic Regression and Random Forest)\n", "- Risk and profit calculations\n", "- Cutoff optimization for approval strategy\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import pandas as pd\n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "from sklearn.model_selection import train_test_split\n", "from sklearn.linear_model import LogisticRegression\n", "from sklearn.ensemble import RandomForestClassifier\n", "from sklearn.metrics import roc_auc_score, roc_curve, confusion_matrix, classification_report\n", "\n", "# Display settings\n", "pd.set_option('display.max_columns', 50)\n", "\n", "# Load dataset\n", "df = pd.read_csv('credit_risk_dataset.csv')\n", "df.head()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 1. Basic Data Inspection\n", "We first look at the structure of the dataset, data types, and basic statistics."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Shape and dtypes\n", "print('Shape:', df.shape)\n", "print('\\nData types:')\n", "print(df.dtypes)\n", "\n", "# Summary statistics for numeric columns\n", "df.describe().T"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Check target balance\n", "print(df['default_12m'].value_counts(normalize=True))\n", "df['default_12m'].value_counts(normalize=True).plot(kind='bar')\n", "plt.xlabel('Default in 12 months')\n", "plt.ylabel('Proportion')\n", "plt.title('Target Class Distribution')\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 2. Data Cleaning and Feature Engineering\n", "We handle duplicates, basic feature checks, and derive key features such as utilization and months on book."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Remove duplicate rows if any\n", "df = df.drop_duplicates()\n", "\n", "# Ensure utilization is within a reasonable range\n", "df['utilization_rate'] = df['current_balance'] / df['credit_limit']\n", "df['utilization_rate'] = df['utilization_rate'].clip(lower=0, upper=1.5)\n", "\n", "# Months on book is already computed, but ensure non-negative\n", "df['months_on_book'] = df['months_on_book'].clip(lower=0)\n", "\n", "# Simple handling of missing values (if any)\n", "missing = df.isna().mean()\n", "print('Missing value fraction per column:')\n", "print(missing[missing > 0])\n", "\n", "# For this simulated dataset, we expect no missing values. In a real project, we would impute or drop as appropriate."]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 3. Exploratory Data Analysis (EDA)\n", "We explore key drivers of risk: age, income, utilization, late payments, and delinquency history."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Histograms for selected numeric features\n", "numeric_cols = ['age', 'income', 'credit_limit', 'current_balance', 'utilization_rate',\n", "                'num_late_payments_12m', 'max_days_past_due', 'months_on_book']\n", "\n", "df[numeric_cols].hist(figsize=(12, 8), bins=30)\n", "plt.tight_layout()\n", "plt.show()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Default rate by utilization band\n", "util_bins = [0, 0.25, 0.5, 0.75, 1.0, 1.5]\n", "df['util_band'] = pd.cut(df['utilization_rate'], bins=util_bins, include_lowest=True)\n", "util_default = df.groupby('util_band')['default_12m'].mean()\n", "print(util_default)\n", "\n", "util_default.plot(kind='bar')\n", "plt.xlabel('Utilization band')\n", "plt.ylabel('Default rate')\n", "plt.title('Default Rate by Utilization Band')\n", "plt.show()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Correlation matrix for key numeric features\n", "corr_cols = ['age', 'income', 'employment_length_years', 'credit_limit', 'current_balance',\n", "             'utilization_rate', 'num_late_payments_12m', 'max_days_past_due',\n", "             'num_credit_cards', 'delinq_ever', 'months_on_book', 'default_12m']\n", "\n", "corr = df[corr_cols].corr()\n", "plt.figure(figsize=(10, 8))\n", "plt.imshow(corr, interpolation='nearest')\n", "plt.xticks(range(len(corr_cols)), corr_cols, rotation=90)\n", "plt.yticks(range(len(corr_cols)), corr_cols)\n", "plt.title('Correlation Matrix')\n", "plt.colorbar()\n", "plt.tight_layout()\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 4. Modeling Setup\n", "We prepare the feature matrix and target vector, then split into training and test sets."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["target = 'default_12m'\n", "drop_cols = ['account_id', 'account_open_date', 'observation_date', 'util_band']\n", "\n", "features = [c for c in df.columns if c not in drop_cols + [target]]\n", "X = df[features]\n", "y = df[target]\n", "\n", "# Train-test split\n", "X_train, X_test, y_train, y_test = train_test_split(\n", "    X, y, test_size=0.3, random_state=42, stratify=y\n", ")\n", "X_train.shape, X_test.shape"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 5. Logistic Regression Model\n", "We fit a baseline interpretable model and evaluate using AUC and classification metrics."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Fit logistic regression\n", "logit = LogisticRegression(max_iter=1000)\n", "logit.fit(X_train, y_train)\n", "\n", "y_pred_proba_logit = logit.predict_proba(X_test)[:, 1]\n", "y_pred_logit = (y_pred_proba_logit >= 0.5).astype(int)\n", "\n", "auc_logit = roc_auc_score(y_test, y_pred_proba_logit)\n", "print('Logistic Regression AUC:', round(auc_logit, 3))\n", "\n", "print('\\nClassification report (threshold = 0.5):')\n", "print(classification_report(y_test, y_pred_logit))\n", "\n", "cm_logit = confusion_matrix(y_test, y_pred_logit)\n", "print('Confusion matrix:\\n', cm_logit)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# ROC curve for logistic regression\n", "fpr_logit, tpr_logit, _ = roc_curve(y_test, y_pred_proba_logit)\n", "plt.figure()\n", "plt.plot(fpr_logit, tpr_logit, label='Logistic Regression')\n", "plt.plot([0, 1], [0, 1], linestyle='--')\n", "plt.xlabel('False Positive Rate')\n", "plt.ylabel('True Positive Rate')\n", "plt.title('ROC Curve - Logistic Regression')\n", "plt.legend()\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 6. Random Forest Model\n", "We fit a non-linear model to potentially capture more complex patterns and compare performance."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["rf = RandomForestClassifier(\n", "    n_estimators=300,\n", "    max_depth=None,\n", "    min_samples_split=10,\n", "    min_samples_leaf=5,\n", "    random_state=42,\n", "    n_jobs=-1\n", ")\n", "rf.fit(X_train, y_train)\n", "\n", "y_pred_proba_rf = rf.predict_proba(X_test)[:, 1]\n", "y_pred_rf = (y_pred_proba_rf >= 0.5).astype(int)\n", "\n", "auc_rf = roc_auc_score(y_test, y_pred_proba_rf)\n", "print('Random Forest AUC:', round(auc_rf, 3))\n", "\n", "print('\\nClassification report (threshold = 0.5):')\n", "print(classification_report(y_test, y_pred_rf))\n", "\n", "cm_rf = confusion_matrix(y_test, y_pred_rf)\n", "print('Confusion matrix:\\n', cm_rf)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# ROC curve comparison\n", "fpr_rf, tpr_rf, _ = roc_curve(y_test, y_pred_proba_rf)\n", "\n", "plt.figure()\n", "plt.plot(fpr_logit, tpr_logit, label='Logistic Regression')\n", "plt.plot(fpr_rf, tpr_rf, label='Random Forest')\n", "plt.plot([0, 1], [0, 1], linestyle='--')\n", "plt.xlabel('False Positive Rate')\n", "plt.ylabel('True Positive Rate')\n", "plt.title('ROC Curves - Model Comparison')\n", "plt.legend()\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### 6.1 Feature Importance (Random Forest)\n", "We inspect which features are most influential in the Random Forest model."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["importances = rf.feature_importances_\n", "feat_imp = pd.Series(importances, index=features).sort_values(ascending=False)\n", "print(feat_imp.head(15))\n", "\n", "plt.figure(figsize=(8, 6))\n", "feat_imp.head(15).plot(kind='barh')\n", "plt.gca().invert_yaxis()\n", "plt.xlabel('Importance')\n", "plt.title('Top 15 Feature Importances - Random Forest')\n", "plt.tight_layout()\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 7. Risk and Profit Calculations\n", "Using the Random Forest model (higher AUC in many cases), we compute expected loss and expected profit per account."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Choose Random Forest as the production model for this analysis\n", "df_test = X_test.copy()\n", "df_test['default_12m'] = y_test.values\n", "\n", "df_test['pd_hat'] = y_pred_proba_rf\n", "\n", "# Financial assumptions\n", "df_test['exposure'] = df_test['credit_limit']\n", "LGD_rate = 0.6\n", "df_test['LGD_amount'] = df_test['exposure'] * LGD_rate\n", "df_test['annual_interest_revenue'] = df_test['exposure'] * 0.18\n", "\n", "df_test['Expected_Loss'] = df_test['pd_hat'] * df_test['LGD_amount']\n", "df_test['Expected_Profit'] = (1 - df_test['pd_hat']) * df_test['annual_interest_revenue'] - df_test['Expected_Loss']\n", "\n", "df_test[['pd_hat', 'exposure', 'LGD_amount', 'annual_interest_revenue',\n", "         'Expected_Loss', 'Expected_Profit']].head()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 8. Cutoff Optimization\n", "We simulate different approval strategies by varying the PD cutoff. Accounts with predicted PD below the cutoff are approved."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["cutoffs = np.arange(0.01, 0.31, 0.01)\n", "results = []\n", "\n", "for c in cutoffs:\n", "    approved = df_test[df_test['pd_hat'] <= c]\n", "    if len(approved) == 0:\n", "        continue\n", "    total_profit = approved['Expected_Profit'].sum()\n", "    avg_pd = approved['pd_hat'].mean()\n", "    total_expected_loss = approved['Expected_Loss'].sum()\n", "    results.append({\n", "        'cutoff': c,\n", "        'n_approved': len(approved),\n", "        'total_profit': total_profit,\n", "        'avg_pd': avg_pd,\n", "        'total_expected_loss': total_expected_loss\n", "    })\n", "\n", "results_df = pd.DataFrame(results)\n", "results_df.sort_values('total_profit', ascending=False).head()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Plot cutoff vs total expected profit\n", "plt.figure()\n", "plt.plot(results_df['cutoff'], results_df['total_profit'])\n", "plt.xlabel('PD Cutoff')\n", "plt.ylabel('Total Expected Profit')\n", "plt.title('Total Expected Profit vs PD Cutoff')\n", "plt.show()\n", "\n", "# Plot cutoff vs average PD of approved portfolio\n", "plt.figure()\n", "plt.plot(results_df['cutoff'], results_df['avg_pd'])\n", "plt.xlabel('PD Cutoff')\n", "plt.ylabel('Average PD of Approved Accounts')\n", "plt.title('Average PD vs PD Cutoff')\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 9. Summary and Recommended Strategy\n", "We identify a reasonable PD cutoff that balances profit and risk."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Identify cutoff with maximum profit\n", "best_row = results_df.loc[results_df['total_profit'].idxmax()]\n", "print('Best cutoff by total expected profit:')\n", "print(best_row)\n", "\n", "print('\\nRecommended PD cutoff (approx):', round(best_row['cutoff'], 3))\n", "print('Number of approved accounts:', int(best_row['n_approved']))\n", "print('Average PD of approved accounts:', round(best_row['avg_pd'], 4))\n", "print('Total expected loss for approved accounts:', round(best_row['total_expected_loss'], 2))\n", "print('Total expected profit for approved accounts:', round(best_row['total_profit'], 2))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Interpretation\n", "- The **Random Forest** model typically delivers stronger discriminatory power than the baseline logistic regression in this setup.\n", "- By sweeping the PD cutoff, we quantify the trade-off between **volume** (number of approved accounts), **risk** (expected loss), and **profit**.\n", "- The recommended cutoff near the profit-maximizing point can be proposed as the **risk appetite threshold** for the portfolio.\n", "- In a real-world setting, this cutoff would be further stress-tested and aligned with regulatory, capital, and business constraints."]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"file_extension": ".py", "mimetype": "text/x-python", "name": "python"}}, "nbformat": 4, "nbformat_minor": 5}